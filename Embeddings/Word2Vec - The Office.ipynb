{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import re, string, unicodedata\n",
    "from collections import defaultdict\n",
    "import multiprocessing\n",
    "\n",
    "# cleaning and preprocessing\n",
    "from contractions import CONTRACTION_MAP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "# bigrams\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# logging to monitor gensim\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  season  episode  scene  \\\n",
       "0   1       1        1      1   \n",
       "1   2       1        1      1   \n",
       "2   3       1        1      1   \n",
       "3   4       1        1      1   \n",
       "4   5       1        1      1   \n",
       "\n",
       "                                           line_text  speaker  deleted  \n",
       "0  All right Jim. Your quarterlies look very good...  Michael    False  \n",
       "1         Oh, I told you. I couldn't close it. So...      Jim    False  \n",
       "2  So you've come to the master for guidance? Is ...  Michael    False  \n",
       "3         Actually, you called me in here, but yeah.      Jim    False  \n",
       "4    All right. Well, let me show you how it's done.  Michael    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://query.data.world/s/nu4cetyeefkjloxph4ytsbis5zejjg'); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59909, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>line_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59907</th>\n",
       "      <td>Jim</td>\n",
       "      <td>I sold paper at this company for 12 years. My ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59908</th>\n",
       "      <td>Pam</td>\n",
       "      <td>I thought it was weird when you picked us to m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      speaker                                          line_text\n",
       "59907     Jim  I sold paper at this company for 12 years. My ...\n",
       "59908     Pam  I thought it was weird when you picked us to m..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering columns\n",
    "COLUMNS = [\"speaker\", \"line_text\"]\n",
    "df = df[COLUMNS];\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker      0\n",
       "line_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "Cleaning pipeline consists of:\n",
    "\n",
    "- Expanding contractions (y'all -> you all)\n",
    "- Lowercase\n",
    "- Remove punctuations, stopwords, special characters, non-alphanumeric\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contractions helper function\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contracted'] = df['line_text'].apply(lambda x: expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "def tokenize(text):\n",
    "    tweet_tokens = re.split('\\W+', text)\n",
    "    return tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['contracted'].apply(lambda x: tokenize(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalize'] = df['tokens'].apply(lambda x: normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>line_text</th>\n",
       "      <th>contracted</th>\n",
       "      <th>tokens</th>\n",
       "      <th>normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>[All, right, Jim, Your, quarterlies, look, ver...</td>\n",
       "      <td>[right, jim, quarterly, look, good, thing, lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Oh, I told you. I could not close it. So...</td>\n",
       "      <td>[Oh, I, told, you, I, could, not, close, it, S...</td>\n",
       "      <td>[oh, told, could, close]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>So you have come to the master for guidance? I...</td>\n",
       "      <td>[So, you, have, come, to, the, master, for, gu...</td>\n",
       "      <td>[come, master, guidance, say, grasshopper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>[Actually, you, called, me, in, here, but, yea...</td>\n",
       "      <td>[actually, call, yeah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>All right. Well, let me show you how it is done.</td>\n",
       "      <td>[All, right, Well, let, me, show, you, how, it...</td>\n",
       "      <td>[right, well, let, show, do]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                          line_text  \\\n",
       "0  Michael  All right Jim. Your quarterlies look very good...   \n",
       "1      Jim         Oh, I told you. I couldn't close it. So...   \n",
       "2  Michael  So you've come to the master for guidance? Is ...   \n",
       "3      Jim         Actually, you called me in here, but yeah.   \n",
       "4  Michael    All right. Well, let me show you how it's done.   \n",
       "\n",
       "                                          contracted  \\\n",
       "0  All right Jim. Your quarterlies look very good...   \n",
       "1        Oh, I told you. I could not close it. So...   \n",
       "2  So you have come to the master for guidance? I...   \n",
       "3         Actually, you called me in here, but yeah.   \n",
       "4   All right. Well, let me show you how it is done.   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [All, right, Jim, Your, quarterlies, look, ver...   \n",
       "1  [Oh, I, told, you, I, could, not, close, it, S...   \n",
       "2  [So, you, have, come, to, the, master, for, gu...   \n",
       "3  [Actually, you, called, me, in, here, but, yea...   \n",
       "4  [All, right, Well, let, me, show, you, how, it...   \n",
       "\n",
       "                                           normalize  \n",
       "0  [right, jim, quarterly, look, good, thing, lib...  \n",
       "1                           [oh, told, could, close]  \n",
       "2         [come, master, guidance, say, grasshopper]  \n",
       "3                             [actually, call, yeah]  \n",
       "4                       [right, well, let, show, do]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitching together\n",
    "tokens = []\n",
    "for i,d in enumerate(df['normalize']):\n",
    "    tokens.append(' '.join(d))\n",
    "    \n",
    "df['clean_text'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>line_text</th>\n",
       "      <th>contracted</th>\n",
       "      <th>tokens</th>\n",
       "      <th>normalize</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>[All, right, Jim, Your, quarterlies, look, ver...</td>\n",
       "      <td>[right, jim, quarterly, look, good, thing, lib...</td>\n",
       "      <td>right jim quarterly look good thing library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Oh, I told you. I could not close it. So...</td>\n",
       "      <td>[Oh, I, told, you, I, could, not, close, it, S...</td>\n",
       "      <td>[oh, told, could, close]</td>\n",
       "      <td>oh told could close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>So you have come to the master for guidance? I...</td>\n",
       "      <td>[So, you, have, come, to, the, master, for, gu...</td>\n",
       "      <td>[come, master, guidance, say, grasshopper]</td>\n",
       "      <td>come master guidance say grasshopper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>[Actually, you, called, me, in, here, but, yea...</td>\n",
       "      <td>[actually, call, yeah]</td>\n",
       "      <td>actually call yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>All right. Well, let me show you how it is done.</td>\n",
       "      <td>[All, right, Well, let, me, show, you, how, it...</td>\n",
       "      <td>[right, well, let, show, do]</td>\n",
       "      <td>right well let show do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                          line_text  \\\n",
       "0  Michael  All right Jim. Your quarterlies look very good...   \n",
       "1      Jim         Oh, I told you. I couldn't close it. So...   \n",
       "2  Michael  So you've come to the master for guidance? Is ...   \n",
       "3      Jim         Actually, you called me in here, but yeah.   \n",
       "4  Michael    All right. Well, let me show you how it's done.   \n",
       "\n",
       "                                          contracted  \\\n",
       "0  All right Jim. Your quarterlies look very good...   \n",
       "1        Oh, I told you. I could not close it. So...   \n",
       "2  So you have come to the master for guidance? I...   \n",
       "3         Actually, you called me in here, but yeah.   \n",
       "4   All right. Well, let me show you how it is done.   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [All, right, Jim, Your, quarterlies, look, ver...   \n",
       "1  [Oh, I, told, you, I, could, not, close, it, S...   \n",
       "2  [So, you, have, come, to, the, master, for, gu...   \n",
       "3  [Actually, you, called, me, in, here, but, yea...   \n",
       "4  [All, right, Well, let, me, show, you, how, it...   \n",
       "\n",
       "                                           normalize  \\\n",
       "0  [right, jim, quarterly, look, good, thing, lib...   \n",
       "1                           [oh, told, could, close]   \n",
       "2         [come, master, guidance, say, grasshopper]   \n",
       "3                             [actually, call, yeah]   \n",
       "4                       [right, well, let, show, do]   \n",
       "\n",
       "                                    clean_text  \n",
       "0  right jim quarterly look good thing library  \n",
       "1                          oh told could close  \n",
       "2         come master guidance say grasshopper  \n",
       "3                           actually call yeah  \n",
       "4                       right well let show do  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59909, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker       0\n",
       "line_text     0\n",
       "contracted    0\n",
       "tokens        0\n",
       "normalize     0\n",
       "clean_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases() takes a list of words as input; so passing column 'normalize'\n",
    "sent = [w for w in df['normalize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:47:55: collecting all words and their counts\n",
      "INFO - 10:47:55: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #5000, processed 28759 words and 22892 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #10000, processed 56658 words and 41058 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #15000, processed 83948 words and 57678 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #20000, processed 113156 words and 74958 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #25000, processed 142341 words and 91066 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #30000, processed 169750 words and 105143 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #35000, processed 197084 words and 119044 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #40000, processed 224977 words and 133115 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #45000, processed 253953 words and 147463 word types\n",
      "INFO - 10:47:55: PROGRESS: at sentence #50000, processed 283751 words and 162812 word types\n",
      "INFO - 10:47:56: PROGRESS: at sentence #55000, processed 312300 words and 176900 word types\n",
      "INFO - 10:47:56: collected 191100 word types from a corpus of 341427 words (unigram + bigrams) and 59909 sentences\n",
      "INFO - 10:47:56: using 191100 counts as vocab in Phrases<0 vocab, min_count=25, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "# Create relevant phrases from list of sentences\n",
    "phrases = Phrases(sent, min_count=25, progress_per=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:48:33: source_vocab length 191100\n",
      "INFO - 10:48:35: Phraser built with 86 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16436"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "        \n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'get', 'know', 'oh', 'like', 'yeah', 'okay', 'well', 'right', 'michael']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most freq\n",
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wastepaper',\n",
       " 'spencer',\n",
       " 'whass',\n",
       " 'rodham',\n",
       " 'ringie',\n",
       " 'dingie',\n",
       " 'packman',\n",
       " 'godzillary',\n",
       " 'unnecessarily',\n",
       " 'daniqua']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# least freq\n",
    "sorted(word_freq, key=word_freq.get, reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# cores\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec()\n",
    "\n",
    "Set up the parameters.\n",
    "\n",
    "Leaving it uninitialized purposefully by not supplying the parameter *sentences*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=10,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .build_vocab()\n",
    "\n",
    "Builds vocab from sequence of sentences and the model gets initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:03:48: collecting all words and their counts\n",
      "INFO - 11:03:48: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #5000, processed 28172 words, keeping 4186 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #10000, processed 55444 words, keeping 6148 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #15000, processed 82180 words, keeping 7753 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #20000, processed 110781 words, keeping 9218 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #25000, processed 139323 words, keeping 10460 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #30000, processed 166056 words, keeping 11344 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #35000, processed 192812 words, keeping 12262 word types\n",
      "INFO - 11:03:48: PROGRESS: at sentence #40000, processed 220161 words, keeping 13147 word types\n",
      "INFO - 11:03:49: PROGRESS: at sentence #45000, processed 248629 words, keeping 13932 word types\n",
      "INFO - 11:03:49: PROGRESS: at sentence #50000, processed 277973 words, keeping 14869 word types\n",
      "INFO - 11:03:49: PROGRESS: at sentence #55000, processed 306021 words, keeping 15676 word types\n",
      "INFO - 11:03:49: collected 16436 word types from a corpus of 334617 raw words and 59909 sentences\n",
      "INFO - 11:03:49: Loading a fresh vocabulary\n",
      "INFO - 11:03:49: effective_min_count=10 retains 3300 unique words (20% of original 16436, drops 13136)\n",
      "INFO - 11:03:49: effective_min_count=10 leaves 303832 word corpus (90% of original 334617, drops 30785)\n",
      "INFO - 11:03:49: deleting the raw counts dictionary of 16436 items\n",
      "INFO - 11:03:49: sample=6e-05 downsamples 1014 most-common words\n",
      "INFO - 11:03:49: downsampling leaves estimated 124642 word corpus (41.0% of prior 303832)\n",
      "INFO - 11:03:49: estimated required memory for 3300 words and 300 dimensions: 9570000 bytes\n",
      "INFO - 11:03:49: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=5000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:06:52: training model with 7 workers on 3300 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 11:06:53: EPOCH 1 - PROGRESS: at 51.35% examples, 62215 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:06:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:06:54: EPOCH - 1 : training on 334617 raw words (124548 effective words) took 1.6s, 80014 effective words/s\n",
      "INFO - 11:06:55: EPOCH 2 - PROGRESS: at 86.88% examples, 103042 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:06:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:06:55: EPOCH - 2 : training on 334617 raw words (124409 effective words) took 1.2s, 106672 effective words/s\n",
      "INFO - 11:06:56: EPOCH 3 - PROGRESS: at 86.88% examples, 104323 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:06:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:06:56: EPOCH - 3 : training on 334617 raw words (124928 effective words) took 1.2s, 105673 effective words/s\n",
      "INFO - 11:06:57: EPOCH 4 - PROGRESS: at 89.82% examples, 108881 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:06:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:06:57: EPOCH - 4 : training on 334617 raw words (124831 effective words) took 1.1s, 109713 effective words/s\n",
      "INFO - 11:06:58: EPOCH 5 - PROGRESS: at 86.88% examples, 105337 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:06:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:06:58: EPOCH - 5 : training on 334617 raw words (124807 effective words) took 1.2s, 108120 effective words/s\n",
      "INFO - 11:06:59: EPOCH 6 - PROGRESS: at 60.63% examples, 73220 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:00: EPOCH - 6 : training on 334617 raw words (124691 effective words) took 1.5s, 85125 effective words/s\n",
      "INFO - 11:07:01: EPOCH 7 - PROGRESS: at 89.82% examples, 107449 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:01: EPOCH - 7 : training on 334617 raw words (124650 effective words) took 1.1s, 109568 effective words/s\n",
      "INFO - 11:07:02: EPOCH 8 - PROGRESS: at 86.88% examples, 105421 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:02: EPOCH - 8 : training on 334617 raw words (124623 effective words) took 1.1s, 109404 effective words/s\n",
      "INFO - 11:07:03: EPOCH 9 - PROGRESS: at 86.88% examples, 105498 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:03: EPOCH - 9 : training on 334617 raw words (124525 effective words) took 1.2s, 107125 effective words/s\n",
      "INFO - 11:07:04: EPOCH 10 - PROGRESS: at 86.88% examples, 104722 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:04: EPOCH - 10 : training on 334617 raw words (124843 effective words) took 1.2s, 108095 effective words/s\n",
      "INFO - 11:07:05: EPOCH 11 - PROGRESS: at 86.88% examples, 106380 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:05: EPOCH - 11 : training on 334617 raw words (124793 effective words) took 1.2s, 108502 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:07:06: EPOCH 12 - PROGRESS: at 48.15% examples, 58506 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:07: EPOCH - 12 : training on 334617 raw words (124900 effective words) took 1.6s, 79312 effective words/s\n",
      "INFO - 11:07:08: EPOCH 13 - PROGRESS: at 83.93% examples, 104248 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:08: EPOCH - 13 : training on 334617 raw words (124877 effective words) took 1.2s, 107757 effective words/s\n",
      "INFO - 11:07:09: EPOCH 14 - PROGRESS: at 86.88% examples, 107394 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:09: EPOCH - 14 : training on 334617 raw words (124638 effective words) took 1.1s, 109313 effective words/s\n",
      "INFO - 11:07:10: EPOCH 15 - PROGRESS: at 86.88% examples, 106749 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:11: EPOCH - 15 : training on 334617 raw words (124657 effective words) took 1.1s, 109857 effective words/s\n",
      "INFO - 11:07:12: EPOCH 16 - PROGRESS: at 86.88% examples, 103669 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:12: EPOCH - 16 : training on 334617 raw words (124655 effective words) took 1.2s, 105993 effective words/s\n",
      "INFO - 11:07:13: EPOCH 17 - PROGRESS: at 63.70% examples, 77490 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:13: EPOCH - 17 : training on 334617 raw words (124809 effective words) took 1.4s, 88848 effective words/s\n",
      "INFO - 11:07:14: EPOCH 18 - PROGRESS: at 86.88% examples, 105833 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:14: EPOCH - 18 : training on 334617 raw words (125000 effective words) took 1.2s, 107817 effective words/s\n",
      "INFO - 11:07:15: EPOCH 19 - PROGRESS: at 86.88% examples, 106848 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:15: EPOCH - 19 : training on 334617 raw words (124470 effective words) took 1.1s, 108704 effective words/s\n",
      "INFO - 11:07:16: EPOCH 20 - PROGRESS: at 83.93% examples, 100311 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:17: EPOCH - 20 : training on 334617 raw words (124427 effective words) took 1.2s, 104722 effective words/s\n",
      "INFO - 11:07:18: EPOCH 21 - PROGRESS: at 83.93% examples, 101541 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:18: EPOCH - 21 : training on 334617 raw words (124602 effective words) took 1.2s, 104138 effective words/s\n",
      "INFO - 11:07:19: EPOCH 22 - PROGRESS: at 63.70% examples, 77271 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:19: EPOCH - 22 : training on 334617 raw words (125065 effective words) took 1.4s, 88077 effective words/s\n",
      "INFO - 11:07:20: EPOCH 23 - PROGRESS: at 89.82% examples, 106077 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:07:20: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:20: EPOCH - 23 : training on 334617 raw words (124703 effective words) took 1.1s, 108991 effective words/s\n",
      "INFO - 11:07:21: EPOCH 24 - PROGRESS: at 83.93% examples, 103847 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:22: EPOCH - 24 : training on 334617 raw words (124742 effective words) took 1.2s, 108155 effective words/s\n",
      "INFO - 11:07:23: EPOCH 25 - PROGRESS: at 86.88% examples, 107707 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:23: EPOCH - 25 : training on 334617 raw words (124782 effective words) took 1.1s, 110856 effective words/s\n",
      "INFO - 11:07:24: EPOCH 26 - PROGRESS: at 86.88% examples, 106352 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:24: EPOCH - 26 : training on 334617 raw words (124323 effective words) took 1.1s, 110410 effective words/s\n",
      "INFO - 11:07:25: EPOCH 27 - PROGRESS: at 63.70% examples, 77029 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:25: EPOCH - 27 : training on 334617 raw words (124778 effective words) took 1.4s, 88691 effective words/s\n",
      "INFO - 11:07:26: EPOCH 28 - PROGRESS: at 89.82% examples, 108893 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:26: EPOCH - 28 : training on 334617 raw words (124878 effective words) took 1.1s, 110213 effective words/s\n",
      "INFO - 11:07:27: EPOCH 29 - PROGRESS: at 86.88% examples, 106113 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:28: EPOCH - 29 : training on 334617 raw words (124736 effective words) took 1.1s, 109363 effective words/s\n",
      "INFO - 11:07:29: EPOCH 30 - PROGRESS: at 86.88% examples, 106117 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:07:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:07:29: EPOCH - 30 : training on 334617 raw words (124936 effective words) took 1.1s, 110183 effective words/s\n",
      "INFO - 11:07:29: training on a 10038510 raw words (3741626 effective words) took 36.7s, 101827 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.61 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:08:09: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# make model memory efficient\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the model\n",
    "\n",
    "### Most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stare', 0.9281713962554932),\n",
       " ('hang_phone', 0.9271564483642578),\n",
       " ('leaf', 0.9229561686515808),\n",
       " ('annex', 0.9186846017837524),\n",
       " ('jim', 0.9086365103721619),\n",
       " ('quietly', 0.9002681970596313),\n",
       " ('excuse', 0.8983709812164307),\n",
       " ('smile', 0.8971234560012817),\n",
       " ('walk', 0.8954806327819824),\n",
       " ('exit', 0.8950591087341309)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['michael'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dwight_schrute', 0.9417242407798767),\n",
       " ('paper_company', 0.9340528249740601),\n",
       " ('dunder_mifflin', 0.9315226078033447),\n",
       " ('introduce', 0.905677318572998),\n",
       " ('regional_manager', 0.9046109914779663),\n",
       " ('jim_halpert', 0.9032676815986633),\n",
       " ('david_wallace', 0.8575462102890015),\n",
       " ('robert_california', 0.8443684577941895),\n",
       " ('mr', 0.8369607925415039),\n",
       " ('howard', 0.8282136917114258)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['michael_scott'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pam', 0.9532161951065063),\n",
       " ('stare', 0.9458998441696167),\n",
       " ('quietly', 0.9405232667922974),\n",
       " ('whisper', 0.9315623044967651),\n",
       " ('annex', 0.9296285510063171),\n",
       " ('nod', 0.9281949996948242),\n",
       " ('smile', 0.9257539510726929),\n",
       " ('shake_head', 0.9235219955444336),\n",
       " ('leaf', 0.9179366230964661),\n",
       " ('erin', 0.9167506694793701)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['jim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nate', 0.8701183199882507),\n",
       " ('friendly', 0.863349437713623),\n",
       " ('upper', 0.8486036062240601),\n",
       " ('brand', 0.8473314642906189),\n",
       " ('vp', 0.8464341163635254),\n",
       " ('suspect', 0.8459171056747437),\n",
       " ('injury', 0.8451924324035645),\n",
       " ('director', 0.8450943231582642),\n",
       " ('temporary', 0.8407367467880249),\n",
       " ('claim', 0.8386325836181641)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['warehouse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dunder', 0.9334063529968262),\n",
       " ('mill', 0.9275669455528259),\n",
       " ('chief', 0.9271690845489502),\n",
       " ('regard', 0.9200038909912109),\n",
       " ('former', 0.9177340269088745),\n",
       " ('ceremony', 0.9167332649230957),\n",
       " ('lawyer', 0.9143906831741333),\n",
       " ('cappella', 0.9129273295402527),\n",
       " ('associate', 0.9128299951553345),\n",
       " ('retail', 0.9127031564712524)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['andy_bernard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shy', 0.9073845148086548),\n",
       " ('approach', 0.9008233547210693),\n",
       " ('phyllis', 0.899946928024292),\n",
       " ('kevin', 0.8996772766113281),\n",
       " ('pat', 0.8965698480606079),\n",
       " ('kevins', 0.8955251574516296),\n",
       " ('open_door', 0.8949199914932251),\n",
       " ('shake_head', 0.8947243690490723),\n",
       " ('mary', 0.8944340944290161),\n",
       " ('deangelos', 0.8943274617195129)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['oscar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95321625"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"jim\", \"pam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75328887"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"michael\", \"conference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048027"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"dwight\", \"angela\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8841456"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"jim\", \"dwight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957406"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"andy_bernard\", \"cornell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd-One-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/my-ml/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'creed'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jim', 'dwight', 'creed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dwight'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jim', 'dwight', 'pam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angela'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['michael', 'dwight', 'angela'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cornell'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['andy', 'erin', 'cornell'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-ml",
   "language": "python",
   "name": "my-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
